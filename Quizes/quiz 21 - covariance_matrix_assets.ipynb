{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance of one stock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.14.5 (from -r requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.18.1 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/09/e66eb844daba8680ddff26335d5b4fead77f60f957678243549a8dd4830d/pandas-0.18.1.tar.gz (7.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.3MB 5.3MB/s eta 0:00:01    17% |█████▊                          | 1.3MB 27.8MB/s eta 0:00:01    99% |████████████████████████████████| 7.3MB 32.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 3))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 6.4MB/s ta 0:00:011    77% |████████████████████████▉       | 839kB 21.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.11.0)\n",
      "Collecting zipline===1.2.0 (from -r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d3/689f2a940478b82ac57c751a40460598221fd82b0449a7a8f7eef47a3bcc/zipline-1.2.0.tar.gz (659kB)\n",
      "\u001b[K    100% |████████████████████████████████| 665kB 18.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas==0.18.1->-r requirements.txt (line 2)) (2017.3)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 3)) (2.18.4)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (18.1)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (38.4.0)\n",
      "Collecting Logbook>=0.12.5 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/d9/16ac346f7c0102835814cc9e5b684aaadea101560bb932a2403bd26b2320/Logbook-1.5.3.tar.gz (85kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 16.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests-file>=1.4.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (1.2.1)\n",
      "Collecting pandas-datareader<0.6,>=0.2.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/c5/cc720f531bbde0efeab940de400d0fcc95e87770a3abcd7f90d6d52a3302/pandas_datareader-0.5.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 18.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (0.8.0)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 20.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 18.3MB/s ta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/60/370352f7ef6aa96c52fb001831622f50f923c1d575427d021b8ab3311236/contextlib2-0.6.0.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (6.7)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (0.8.2)\n",
      "Collecting multipledispatch>=0.4.8 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.2.0->-r requirements.txt (line 6)) (1.0.7)\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline===1.2.0->-r requirements.txt (line 6)) (1.1.13)\n",
      "Collecting alembic>=0.7.7 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 16.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/13/f3/cf85f7c3a2dbd1a515d51e1f1676d971abe41bba6f4ab5443240d9a78e5b/sortedcontainers-2.1.0-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/f9/76237755b2020cd74549e98667210b2dd54d3fb17c6f4a62631e61d31225/intervaltree-3.0.2.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/a5/32ed6e10246cd341ca8cc205acea5d208e4053f48a4dced2b1b31d45ba3f/lru-dict-1.1.6.tar.gz\n",
      "Collecting empyrical>=0.4.2 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/9e/9506e8b25464ff57ef93b5ba9092b464b44dc76b717695b126b3c93214a2/empyrical-0.5.3.tar.gz (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 13.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline===1.2.0->-r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 8.4MB/s eta 0:00:01    22% |███████▏                        | 962kB 11.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3)) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 3)) (4.3.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 3)) (2019.11.28)\n",
      "Collecting requests-ftp (from pandas-datareader<0.6,>=0.2.1->zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/ca/14b2ad1e93b5195eeaf56b86b7ecfd5ea2d5754a68d17aeb1e5b9f95b3cf/requests-ftp-0.3.1.tar.gz\n",
      "Collecting python-editor>=0.3 (from alembic>=0.7.7->zipline===1.2.0->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Building wheels for collected packages: pandas, plotly, zipline, Logbook, cyordereddict, bottleneck, bcolz, alembic, intervaltree, lru-dict, empyrical, requests-ftp\n",
      "  Running setup.py bdist_wheel for pandas ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/08/c3/8fdd52954d4b415624cff43c6dd32a22bac90306976a98f4af\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5d/20/7d/b48368c8634b1cb6cc7232833b2780a265d4217c0ad2e3d24c\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/70/07/68b99a8e05dcd1ab194a8e0ccb9e4d0ac5dd6d8d139c7149b4\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for alembic ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/08/99/c0/5a5942f5b9567c59c14aac76f95a70bf11dccc71240b91ebf5\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/ef/06/fbdd555907a7d438fb33e4c8675f771ff1cf41917284c51ebf\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/10/a4/3b/951bd609878a82fd72b9ea23699daf1eaada4ff6f583152876\n",
      "  Running setup.py bdist_wheel for requests-ftp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/98/32/37195e45a3392a73d9f65c488cbea30fe5bad76aaef4d6b020\n",
      "Successfully built pandas plotly zipline Logbook cyordereddict bottleneck bcolz alembic intervaltree lru-dict empyrical requests-ftp\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: numpy, pandas, plotly, Logbook, requests-file, requests-ftp, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, python-editor, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, zipline\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "Successfully installed Logbook-1.5.3 alembic-1.4.1 bcolz-0.12.1 bottleneck-1.3.2 contextlib2-0.6.0.post1 cyordereddict-1.0.0 empyrical-0.5.3 intervaltree-3.0.2 lru-dict-1.1.6 multipledispatch-0.6.0 numpy-1.14.5 pandas-0.18.1 pandas-datareader-0.5.0 plotly-2.2.3 python-editor-1.0.4 requests-file-1.4.3 requests-ftp-0.3.1 sortedcontainers-2.1.0 tables-3.6.1 zipline-1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ABCIndexClass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7bd1771c8e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mquiz_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/quiz_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEquity\u001b[0m  \u001b[0;31m# Required for USEquityPricing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUSEquityPricing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/zipline/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalendars\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_calendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_algo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/zipline/utils/run_algo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtoolz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTradingAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbundles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_portal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataPortal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/zipline/algorithm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExitStack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/tseries/tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtslib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ABCIndexClass'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import quiz_helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import quiz_helper\n",
    "from zipline.data import bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ZIPLINE_ROOT'] = os.path.join(os.getcwd(), '..', '..','data','module_4_quizzes_eod')\n",
    "ingest_func = bundles.csvdir.csvdir_equities(['daily'], quiz_helper.EOD_BUNDLE_NAME)\n",
    "bundles.register(quiz_helper.EOD_BUNDLE_NAME, ingest_func)\n",
    "print('Data Registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipeline engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.factors import AverageDollarVolume\n",
    "from zipline.utils.calendars import get_calendar\n",
    "\n",
    "universe = AverageDollarVolume(window_length=120).top(500) \n",
    "trading_calendar = get_calendar('NYSE') \n",
    "bundle_data = bundles.load(quiz_helper.EOD_BUNDLE_NAME)\n",
    "engine = quiz_helper.build_pipeline_engine(bundle_data, trading_calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data¶\n",
    "With the pipeline engine built, let's get the stocks at the end of the period in the universe we're using. We'll use these tickers to generate the returns data for the our risk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universe_end_date = pd.Timestamp('2016-01-05', tz='UTC')\n",
    "\n",
    "universe_tickers = engine\\\n",
    "    .run_pipeline(\n",
    "        Pipeline(screen=universe),\n",
    "        universe_end_date,\n",
    "        universe_end_date)\\\n",
    "    .index.get_level_values(1)\\\n",
    "    .values.tolist()\n",
    "    \n",
    "universe_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(universe_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.data.data_portal import DataPortal\n",
    "\n",
    "data_portal = DataPortal(\n",
    "    bundle_data.asset_finder,\n",
    "    trading_calendar=trading_calendar,\n",
    "    first_trading_day=bundle_data.equity_daily_bar_reader.first_trading_day,\n",
    "    equity_minute_reader=None,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    adjustment_reader=bundle_data.adjustment_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pricing data helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz_helper import get_pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get pricing data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df = \\\n",
    "    get_pricing(\n",
    "        data_portal,\n",
    "        trading_calendar,\n",
    "        universe_tickers,\n",
    "        universe_end_date - pd.DateOffset(years=5),\n",
    "        universe_end_date)\\\n",
    "    .pct_change()[1:].fillna(0) #convert prices into returns\n",
    "\n",
    "returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at a two stock portfolio\n",
    "\n",
    "Let's pretend we have a portfolio of two stocks.  We'll pick Apple and Microsoft in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_col = returns_df.columns[3]\n",
    "msft_col = returns_df.columns[312]\n",
    "asset_return_1 = returns_df[aapl_col].rename('asset_return_aapl')\n",
    "asset_return_2 = returns_df[msft_col].rename('asset_return_msft')\n",
    "asset_return_df = pd.concat([asset_return_1,asset_return_2],axis=1)\n",
    "asset_return_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor returns\n",
    "Let's make up a \"factor\" by taking an average of all stocks in our list.  You can think of this as an equal weighted index of the 490 stocks, kind of like a measure of the \"market\".  We'll also make another factor by calculating the median of all the stocks.  These are mainly intended to help us generate some data to work with.  We'll go into how some common risk factors are generated later in the lessons.\n",
    "\n",
    "Also note that we're setting axis=1 so that we calculate a value for each time period (row) instead of one value for each column (assets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_return_1 = returns_df.mean(axis=1)\n",
    "factor_return_2 = returns_df.median(axis=1)\n",
    "factor_return_l = [factor_return_1, factor_return_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor exposures\n",
    "\n",
    "Factor exposures refer to how \"exposed\" a stock is to each factor.  We'll get into this more later.  For now, just think of this as one number for each stock, for each of the factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For now, just assume that we're calculating a number for each \n",
    "stock, for each factor, which represents how \"exposed\" each stock is\n",
    "to each factor. \n",
    "We'll discuss how factor exposure is calculated later in the lessons.\n",
    "\"\"\"\n",
    "def get_factor_exposures(factor_return_l, asset_return):\n",
    "    lr = LinearRegression()\n",
    "    X = np.array(factor_return_l).T\n",
    "    y = np.array(asset_return.values)\n",
    "    lr.fit(X,y)\n",
    "    return lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_l = []\n",
    "for i in range(len(asset_return_df.columns)):\n",
    "    factor_exposure_l.append(\n",
    "        get_factor_exposures(factor_return_l,\n",
    "                             asset_return_df[asset_return_df.columns[i]]\n",
    "                            ))\n",
    "    \n",
    "factor_exposure_a = np.array(factor_exposure_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"factor_exposures for asset 1 {factor_exposure_a[0]}\")\n",
    "print(f\"factor_exposures for asset 2 {factor_exposure_a[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Variance of stock 1\n",
    "\n",
    "Calculate the variance of stock 1.  \n",
    "$\\textrm{Var}(f_{1}) = \\beta_{1,1}^2 \\textrm{Var}(f_{1}) + \\beta_{1,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{1,1}\\beta_{1,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_1_1 = factor_exposure_a[0][0]\n",
    "factor_exposure_1_2 = factor_exposure_a[0][1]\n",
    "common_return_1 = factor_exposure_1_1 * factor_return_1 + factor_exposure_1_2 * factor_return_2\n",
    "specific_return_1 = asset_return_1 - common_return_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covm_f1_f2 = np.cov(factor_return_1,factor_return_2,ddof=1) #this calculates a covariance matrix\n",
    "# TODO: get the variance of each factor, and covariances from the covariance matrix covm_f1_f2\n",
    "var_f1 = covm_f1_f2[0, 0]\n",
    "var_f2 = covm_f1_f2[0, 1]\n",
    "cov_f1_f2 = covm_f1_f2[0][1]\n",
    "\n",
    "# TODO: calculate the specific variance.  \n",
    "var_s_1 = np.var(specific_return_1,ddof=1)\n",
    "\n",
    "# TODO: calculate the variance of asset 1 in terms of the factors and specific variance\n",
    "var_asset_1 = (factor_exposure_1_1**2 * var_f1) + \\\n",
    "              (factor_exposure_1_2**2 * var_f2) + \\\n",
    "              2 * (factor_exposure_1_1 * factor_exposure_1_2 * cov_f1_f2) + \\\n",
    "              var_s_1\n",
    "print(f\"variance of asset 1: {var_asset_1:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 2: Variance of stock 2\n",
    "Calculate the variance of stock 2.  \n",
    "$\\textrm{Var}(f_{2}) = \\beta_{2,1}^2 \\textrm{Var}(f_{1}) + \\beta_{2,2}^2 \\textrm{Var}(f_{2}) + 2\\beta_{2,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\textrm{Var}(s_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposure_2_1 = factor_exposure_a[1][0]\n",
    "factor_exposure_2_2 = factor_exposure_a[1][1]\n",
    "common_return_2 = factor_exposure_2_1 * factor_return_1 + factor_exposure_2_2 * factor_return_2\n",
    "specific_return_2 = asset_return_2 - common_return_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice we already calculated the variance and covariances of the factors\n",
    "\n",
    "# TODO: calculate the specific variance of asset 2\n",
    "var_s_2 = p.var(specific_return_2,ddof=1)\n",
    "\n",
    "# TODO: calcualte the variance of asset 2 in terms of the factors and specific variance\n",
    "var_asset_2 = (factor_exposure_2_1**2 * var_f1) + \\\n",
    "              (factor_exposure_2_2**2 * var_f2) + \\\n",
    "              (2 * factor_exposure_2_1 * factor_exposure_2_2 * cov_f1_f2) + \\\n",
    "              var_s_2\n",
    "            \n",
    "print(f\"variance of asset 2: {var_asset_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 3: Covariance of stocks 1 and 2\n",
    "Calculate the covariance of stock 1 and 2.  \n",
    "$\\textrm{Cov}(f_{1},f_{2}) = \\beta_{1,1}\\beta_{2,1}\\textrm{Var}(f_{1}) + \\beta_{1,1}\\beta_{2,2}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,1}\\textrm{Cov}(f_{1},f_{2}) + \\beta_{1,2}\\beta_{2,2}\\textrm{Var}(f_{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the covariance of assets 1 and 2 in terms of the factors\n",
    "cov_asset_1_2 = (factor_exposure_1_1 * factor_exposure_2_1 * var_f1) + \\\n",
    "            (factor_exposure_1_1 * factor_exposure_2_2 * cov_f1_f2) + \\\n",
    "            (factor_exposure_1_2 * factor_exposure_2_1 * cov_f1_f2) + \\\n",
    "            (factor_exposure_1_2 * factor_exposure_2_2 * var_f2)\n",
    "print(f\"covariance of assets 1 and 2: {cov_asset_1_2:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz 4: Do it with Matrices!\n",
    "\n",
    "Create matrices $\\mathbf{F}$, $\\mathbf{B}$ and $\\mathbf{S}$, where  \n",
    "$\\mathbf{F}= \\begin{pmatrix}\n",
    "\\textrm{Var}(f_1) & \\textrm{Cov}(f_1,f_2) \\\\ \n",
    "\\textrm{Cov}(f_2,f_1) & \\textrm{Var}(f_2) \n",
    "\\end{pmatrix}$\n",
    "is the covariance matrix of factors,  \n",
    "\n",
    "$\\mathbf{B} = \\begin{pmatrix}\n",
    "\\beta_{1,1}, \\beta_{1,2}\\\\ \n",
    "\\beta_{2,1}, \\beta_{2,2}\n",
    "\\end{pmatrix}$ \n",
    "is the matrix of factor exposures, and  \n",
    "\n",
    "$\\mathbf{S} = \\begin{pmatrix}\n",
    "\\textrm{Var}(s_i) & 0\\\\ \n",
    "0 & \\textrm{Var}(s_j)\n",
    "\\end{pmatrix}$\n",
    "is the matrix of specific variances.  \n",
    "\n",
    "Then calculate $\\mathbf{BFB}^T$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: covariance matrix of factors\n",
    "F = covm_f1_f2\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: matrix of factor exposures\n",
    "B = factor_exposure_a\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: for diagonal matrices\n",
    "You can try using [numpy.diag](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.diag.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: matrix of specific variances\n",
    "S = np.diag([var_s_1,var_s_2])\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: covariance matrix of assets\n",
    "covm_assets = B.dot(F).dot(B.T) + S\n",
    "print(f\"covariance matrix of assets 1 and 2 \\n{covm_assets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "[Solution notebook](covariance_matrix_assets_solution.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
